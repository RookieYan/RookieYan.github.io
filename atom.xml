<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://RookieYan.github.io</id>
    <title>一个白痴</title>
    <updated>2020-05-05T16:52:46.020Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://RookieYan.github.io"/>
    <link rel="self" href="https://RookieYan.github.io/atom.xml"/>
    <subtitle>闫。</subtitle>
    <logo>https://RookieYan.github.io/images/avatar.png</logo>
    <icon>https://RookieYan.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 一个白痴</rights>
    <entry>
        <title type="html"><![CDATA[ [2020-05-06]MySQL（三）事务隔离级别]]></title>
        <id>https://RookieYan.github.io/post/2020-05-06mysqlsan-shi-wu-ge-chi-ji-bie/</id>
        <link href="https://RookieYan.github.io/post/2020-05-06mysqlsan-shi-wu-ge-chi-ji-bie/">
        </link>
        <updated>2020-05-05T16:49:20.000Z</updated>
        <content type="html"><![CDATA[<pre><code>占坑..
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ [2020-05-05]GitHub查找开源项目小技巧]]></title>
        <id>https://RookieYan.github.io/post/2020-05-05github-cha-zhao-kai-yuan-xiang-mu-xiao-ji-qiao/</id>
        <link href="https://RookieYan.github.io/post/2020-05-05github-cha-zhao-kai-yuan-xiang-mu-xiao-ji-qiao/">
        </link>
        <updated>2020-05-05T14:43:56.000Z</updated>
        <content type="html"><![CDATA[<p><strong>in:name example 名字中有“example”</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690512719.png" alt="" loading="lazy"></p>
<p><strong>in:readme example readme中有“example”</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690541237.png" alt="" loading="lazy"></p>
<p><strong>in:description example 描述中有“example”</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690568233.png" alt="" loading="lazy"></p>
<p><strong>stars:&gt;1000 star&gt;1000</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690601054.png" alt="" loading="lazy"></p>
<p><strong>forks:&gt;1000 fork&gt;1000</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690622634.png" alt="" loading="lazy"></p>
<p><strong>pushed:&gt;2019-09-01 2019年9月1日后有更新的</strong><br>
<img src="https://RookieYan.github.io/post-images/1588690642909.png" alt="" loading="lazy"></p>
<p><strong>详细内容可以看这篇文档 <a href="https://help.github.com/cn/github/searching-for-information-on-github/searching-for-repositories">在GitHub上搜索</a></strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ [2020-04-18]MySQL（二）RedoLog和BinLog]]></title>
        <id>https://RookieYan.github.io/post/2020-04-18mysqler-redolog-he-binlog/</id>
        <link href="https://RookieYan.github.io/post/2020-04-18mysqler-redolog-he-binlog/">
        </link>
        <updated>2020-05-01T16:04:49.000Z</updated>
        <content type="html"><![CDATA[<!-- more -->
<p>  今天说一下MySQL的两个日志模块，分别是BinLog和RedoLog。<br>
  可能有的研发同学会听到DBA同事说MySQL可以恢复到半个月内的任意一秒的状态，在惊奇的同时，可能会好奇是怎么实现的。我们今天就来聊聊这个事儿。</p>
<p>  假如我们现在有一张表T，只有主键Id和一个整型字段 c，然后现在我们要将Id=2这一行的值加1，那么SQL语句应该这么写：</p>
<pre><code>update T set c=c+1 where ID=2;
</code></pre>
<p>  从上一篇<a href="https://rookieyan.github.io/post/2020-04-18mysqlyi-sql-de-zhi-xing-liu-cheng/">MySQL（一）SQL的执行流程</a>我们基本可以很明确这条更新的SQL语句的执行流程会和查询流程一样把整个流程走一遍。前面我们也有说过，在对表做更新操作的时候，跟这个表有关的查询缓存会失效，所以这条语句的执行会把表T上的查询缓存中结果都清空。这也是我们一般不建议使用查询缓存的原因。<br>
<img src="https://RookieYan.github.io/post-images/1588350320310.png" alt="" loading="lazy"><br>
  接下来分析器会通过词法和语法解析知道这是一条更新语句。优化器会决定要使用ID对应的主键索引。执行器负责具体的执行操作，找到对应的这一行，然后更新。</p>
<p>  和查询流程不一样的是，在更新流程中，会涉及到两个比较重要的日志模块。他们正是我们今天要讨论的主角：<strong>redolog（重做日志）和binlog（归档日志）</strong>。 如果接触过MySQL，那么这两个词肯定是绕不过去的。并且这两个日志模块在设计上也有很多有意思的地方，可以将设计思路运用到自己平时的设计和开发中。</p>
<h2 id="1-redo-log"><strong>1. redo log</strong></h2>
<p>  有一个🌰可以很好的解释这个日志模块。《孔乙己》那篇文章中，酒馆老板有一个小黑板和一本账本，专门记录客人赊账的情况。如果有人要赊账或者还账的话，酒馆老板一般有两种做法：</p>
<ul>
<li>把账本翻出来，找到客人对应的记录，做更新操作。</li>
<li>先在小黑板上记录下来这次的帐，等到打烊后再把账单翻出来核算。</li>
</ul>
<p>  在生意比较忙碌的情况下，酒馆老板一定会选择后者，因为前者是在太麻烦了，需要从账本中准确找到客人的记录（可能还没有索引），数目比较大的话可能还需要用算盘算一下，最后再把结果写到账本上。如果比较忙的情况下。这种方式一定是不可取的。 不如先写在小黑板上，等到空闲的时候，再去把账目同步到账本上。</p>
<p>  同样的在MySQL中也有相似的问题，每一次的更新操作都需要写进磁盘里，然后磁盘也需要找到对应的记录做更新操作。整个过程的IO成本和查找成本都是比较高的。为了解决这个问题，MySQL的设计者就想到了类似于酒馆老板记账的思路来提升效率，减少IO。</p>
<p>  所以小黑板和账单配合的过程，就是MySQL里经常说到的<strong>WAL技术，WAL技术的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本。</strong></p>
<p>  具体来说就是，当有一条记录需要被更新的时候，InnoDB引擎就会先把记录给写到redo log中（小黑板），并且更新内存。 这个时候更新就算完成了。 同时InnoDB会在比较合适的时候，把这个操作记录更新到磁盘中，而这个更新一般会是在系统比较空闲的时候去做的（类似于老板打烊后做的事儿）。</p>
<p>  当然你可能会问，会不会有一种情况，就是今天生意太好了，小黑板都被写满了，那怎么办呢？ 如果是这种情况的话，那么只能让老板停下手中的活，先去把账本更新了，然后擦除黑板上的记录，腾出空间，再写上新的记录。InnoDB的redo log是固定大小的，比如可以配置一组是4个文件，每个文件小为1G，那么这块“小黑板”总共就可以记录4G的操作记录，从头开始写，写到末尾就再从头开始写。如下图所示：<br>
<img src="https://RookieYan.github.io/post-images/1588354832158.png" alt="" loading="lazy"><br>
  write pos是当前记录的位置，一边写一边后移，写到LogFile3的末尾就到了LogFile0的开头继续写，check point是当前要擦除的位置，也是一样要往后移并且循环的，擦除记录前要把记录更新到数据文件中。</p>
<p>  write pos 和 checkpoint 之间的绿色部分是“小黑板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“小黑板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。</p>
<p>  至此，有了redolog，InnoDB就可以保证数据在发生数据库异常重启的时候，之前提交的数据都不会丢失，这个能力称为<strong>crash-safe</strong>。</p>
<h2 id="2-bin-log"><strong>2. bin log</strong></h2>
<p>  前面说过，从整体上来看MySQL分为两部分，一部分是Server层，主要负责功能层面的事情。还有一部分是数据引擎层，主要负责存储相关的事情。上面我们说到的redo log是InnoDB引擎特有的日志，而我们MySQL的Server层也有自己的日志，称为binlog。</p>
<p>  为什么会有两种日志呢？主要是因为最初MySQL的默认引擎是MyISAM，而MyISAM又没有crash-safe的能力，binlog只能用于归档。而InnoDB是另外一家公司以插件的形式引入到MySQL中，既然只依靠binlog没有办法实现crash-safe 那就只好使用redolog实现crash-safe了。</p>
<p>  这两个日志有以下三点不一样：</p>
<ul>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。 也就是说 redolog记录的是具体在哪里做了什么修改，而binlog记录的是SQL语句。</li>
<li>redo log 是循环写的，大小固定，会用完。binlog是可以追加写的，如果一个文件写满了，会生成一个新的文件继续写，不会覆盖掉前面的文件。</li>
</ul>
<p>执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程如下：</p>
<ol>
<li>执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。</li>
<li>引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的 binlog，并把 binlog 写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。</li>
</ol>
<p>更新语句的执行流程图：<br>
<img src="https://RookieYan.github.io/post-images/1588691526032.png" alt="" loading="lazy"><br>
其中带颜色的部分都是在执行器中执行的。 其他的都是在InnoDB内部执行的。</p>
<p>由图上可以看到，最后三步把redolog的写入分成了两部分，一部分prepare和commit，这就是两阶段提交。</p>
<h2 id="3-两阶段提交"><strong>3. 两阶段提交</strong></h2>
<p>  那么为什么要有两阶段提交呢？</p>
<p>  回归到我们最初说到的那个话题上，<strong>怎么让MySQL恢复到半个月内任意一个时间点的状态？</strong></p>
<p>  前面我们说了，binlog是采用追加写的方式，记录MySQL的所有逻辑操作，如果说就可以恢复到半个月内任意一秒的数据的话，那么至少在备份系统中一定保存了这半个月的所有binlog，同时数据库定期做了全库的整库备份。这里的定期，可以是一天一次，也可以是一周一次。</p>
<p>  当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p>
<ul>
<li>先找到最近时间点的整库备份，如果运气比较好，可能是昨天晚上凌晨12点的备份数据，然后把这个备份数据恢复到临时库中。</li>
<li>然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻。</li>
</ul>
<p>  这样你的临时库就和误删之前的线上库一样了，然后就可以把表数据从临时库中取出来，按需放到线上库中。</p>
<p>  说回两阶段提交，由于redolog和binlog是两个独立的逻辑，如果没有两阶段提交，就是要么先写redolog再写binlog。 要么就是先写binlog再写redolog。我们思考一下会出现什么问题。</p>
<p>  仍然用前面的 update 语句来做例子。假设当前 ID=2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？</p>
<ol>
<li><strong>先写redolog后写binlog</strong>，假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。</li>
<li><strong>先写binlog后写redolog</strong>，如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。</li>
</ol>
<p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p>
<p><strong>总结：</strong></p>
<pre><code>使用两阶段提交，在不同时间点崩溃恢复的逻辑:
1.单独依靠redologo无法做到指定某一点的恢复，是不是因为redologo是循环写的，如果要恢复的那一时刻被擦掉了，就无法知道这点的数据变动轨迹，而binlog是追加的方式，在文件完整的前提下，数据的变动轨迹都可以知晓？
2. 最后三步是 
   ①引擎写redolog，并处于prepare状态 
   ②执行器写binlog，成功后，发送commit
   ③引擎刚写入的redolog改变为commit状态
  如果crash发生后 redolog =prepare binlog没有对应写入记录，则回滚
  如果crash发生后 redolog =prepare binlog有对应写入记录，则提交
感觉有点像 1 &amp;&amp; 1= 1 1&amp;&amp;0=0 0&amp;&amp;1=0
3.binlog模式 ①记录sql语句 ②记录更新前后的行 一般是用哪种模式？
</code></pre>
<pre><code>redolog是innodb引擎特有的，为了WAL而存在,更新操作是先写入redolog，之后异步写到数据的磁盘文件中。
假设现在前后更新了2条记录并且都写入binlog后突然宕机，在服务重启后，如果只根据binlog是无法获知当前磁盘上的数据文件中那2条记录的状态是否是最新的（除非从头开始跑一遍binlog），
所以一定要借助redolog才能知道宕机前有哪些记录还没更新到磁盘。
如果存储引擎不支持WAL，也不支持事务回滚，每次更新都是直接更新到数据磁盘中，这应该不需要考虑宕机的问题。
因为WAL的异步写入存在，所以需要解决宕机的恢复问题，需要redolog的协助，而redolog需要和binlog保持状态一致，这又要依靠两阶段提交。
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[[2020-04-21]K3S从0搭建以及集成JenkinsCICD流程]]></title>
        <id>https://RookieYan.github.io/post/2020-04-21k3s-cong-0-da-jian/</id>
        <link href="https://RookieYan.github.io/post/2020-04-21k3s-cong-0-da-jian/">
        </link>
        <updated>2020-04-21T13:24:00.000Z</updated>
        <content type="html"><![CDATA[<h2 id="0-准备工作"><strong>0. 准备工作</strong></h2>
<ul>
<li>首先准备两台ECS（我用的是阿里云的4核8G，买了一个周，准备搞一下）</li>
</ul>
<h2 id="1-环境配置"><strong>1. 环境配置</strong></h2>
<ul>
<li>需要Docker 19.03（如果使用较低版本，则可能会出现K3S无法启动的问题）</li>
</ul>
<ol>
<li>需要把yum 包更新到最新</li>
</ol>
<pre><code>yum  update
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587476469607.png" alt="" loading="lazy"><br>
2. 安装需要的依赖包 yum-util提供yum-config-manager功能，另外两个是devicemapper驱动依赖的。</p>
<pre><code>yum install -y yum-utils  device-mapper-persistent-data  lvm2
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587476490002.png" alt="" loading="lazy"><br>
3. 设置yum源</p>
<pre><code>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://RookieYan.github.io/post-images/1587476599172.png" alt="" loading="lazy"></figure>
<ol start="4">
<li>安装docker，出现输入的界面都输入y</li>
</ol>
<pre><code>yum install  -y docker-ce
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587476923202.png" alt="" loading="lazy"><br>
5. 安装完成查看版本</p>
<pre><code>docker -v
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587476969274.png" alt="" loading="lazy"><br>
6.启动 Docker</p>
<pre><code>/bin/systemctl start docker.service
如果不启动docker 会导致K3S无法正常启动
</code></pre>
<h2 id="2-安装k3smaster"><strong>2. 安装K3SMaster</strong></h2>
<ol>
<li>国内节点比较快</li>
</ol>
<pre><code>curl -sfL https://docs.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -s - server --docker
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://RookieYan.github.io/post-images/1587477633426.png" alt="" loading="lazy"></figure>
<ol start="2">
<li>从上面的安装日志也可以看到kubectl只是个软链接，详细如下所示：</li>
</ol>
<pre><code>which kubectl

ls -l /usr/local/bin/kubectl
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587482331193.png" alt="" loading="lazy"><br>
3. 确认版本信息</p>
<pre><code>kubectl version
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587482516688.png" alt="" loading="lazy"><br>
4. 获取节点信息</p>
<pre><code>kubectl get node -o wide
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587482618242.png" alt="" loading="lazy"><br>
<strong>这两步步明显是存在问题的.. 查了一些资料.. 没能解决..<br>
正确的显示应该是：</strong><br>
<img src="https://RookieYan.github.io/post-images/1587482705796.png" alt="" loading="lazy"><br>
<img src="https://RookieYan.github.io/post-images/1587482682298.png" alt="" loading="lazy"></p>
<p><strong>尝试了好几种方式，后来阴差阳错的解决了.. 需要知道原因！ 解决方式是，无意间在命令行输入了</strong></p>
<pre><code>k3s server &amp; 

k3s server stop
</code></pre>
<p><strong>似乎执行起了什么东西.. 再使用上面的命令，就可以看到master正常启动了..</strong></p>
<p><strong>找到了原因是因为 安装K3S之前未启动Docker!!!!</strong><br>
5. 查看K3S状态</p>
<pre><code>/bin/systemctl status k3s
</code></pre>
<h2 id="3-node节点登录"><strong>3. Node节点登录</strong></h2>
<ol>
<li>K3S_TOKEN是server端的，位于/var/lib/rancher/k3s/server/node-token下</li>
</ol>
<pre><code>cat /var/lib/rancher/k3s/server/node-token
</code></pre>
<p><img src="https://RookieYan.github.io/post-images/1587484770708.png" alt="" loading="lazy"><br>
2. 在agent节点上安装 并且添加到master中</p>
<pre><code>curl -sfL https://docs.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://172.26.XXX.14:6443 K3S_TOKEN=K102edd25b832c1442cffc113ba1dc78cbf1f26921f8481bee022b8a::server:bf20ed594c877be17d03a840 sh -s - --docker

如果填写的是公网IP 则需要去阿里添加安全组 开放6443端口
如果是内网则不需要做相关操作
</code></pre>
<ol start="3">
<li>执行以下命令 检查状态</li>
</ol>
<pre><code>/bin/systemctl status k3s-agent
</code></pre>
<h2 id="4-需要安装maven和git同时把代码pull下来"><strong>4.  需要安装maven和Git同时把代码pull下来</strong></h2>
<ol>
<li>安装JDK<br>
https://blog.csdn.net/qq_42670220/article/details/90753244<br>
安装rz（方便本地包上传到服务器）</li>
</ol>
<pre><code>yum install -y lrzsz 

安装完需要刷新配置
source /etc/profile
</code></pre>
<ol start="2">
<li>安装Maven<br>
https://www.cnblogs.com/cannel/p/11104190.html</li>
</ol>
<pre><code>vim /etc/profile
source /etc/profile
</code></pre>
<ol start="3">
<li>安装Git<br>
https://www.cnblogs.com/wulixia/p/11016684.html</li>
<li>使用Git 把代码pull下来</li>
</ol>
<pre><code>这里需要先配置私钥
ssh-keygen -o

cat cat /root/.ssh/id_rsa.pub

配置到gitblit上

git clone -b devops ssh://yanjianxun@47.93.249.207:29418/~admin/cloud-data-center.git
</code></pre>
<ol start="5">
<li>编写 Dockerfile<br>
跟pom.xml同级目录， 后面会写shell脚本， 这里的Dockerfile 可能没用了。</li>
</ol>
<pre><code>FROM java:8-jdk-alpine
LABEL maintainer sunzhe/www.sunzhe.com
RUN apk upgrade
RUN  apk add -U  tzdata &amp;&amp; \
      ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
COPY ./target/cloud-data-center.jar ./
EXPOSE 12313
CMD java -jar /cloud-data-center.jar &gt; cloud-portal.log.out 2&gt;&amp;1
</code></pre>
<ol start="6">
<li>执行Dockerfile</li>
</ol>
<pre><code>docker build -f Dockerfile -t haimanyun/cloud-data-center:1.0.0 .
</code></pre>
<ol start="7">
<li>编写脚本</li>
</ol>
<pre><code>#!/bin/bash
docker_registry=39.101.204.XXX:5656
kubectl create secret docker-registry registry-pull-secret --docker-server=$docker_registry --docker-username=user1 --docker-password=XXX --docker-email=XXX@qq.com -n kube-system
service=&quot;cloud-data-center&quot;
current_dir=$(pwd)
cd /data/cloud-data-center
echo ${current_dir}
# git checkout devops
# -b devops ssh://yanjianxun@47.93.249.XXX:29418/~admin/cloud-data-center.git
git pull
mvn -f /data/cloud-data-center/pom.xml clean
mvn -f /data/cloud-data-center/pom.xml install
image_name=$docker_registry/k3s/${service}:$(date +%F-%H-%M-%S)
sudo docker build -t ${image_name} .
sudo docker push ${image_name}
echo ${current_dir}
sed -i -r &quot;s#(image: )(.*)#\1$image_name#&quot; ${current_dir}/${service}/${service}.yaml
kubectl apply -f ${current_dir}/${service}/${service}.yaml
</code></pre>
<h2 id="5-安装harbor"><strong>5.  安装harbor</strong></h2>
<ol>
<li>下载，解压 (如果自家网络好，可以下载下来再上传到服务器)</li>
</ol>
<pre><code>wget https://github.com/goharbor/harbor/releases/download/v1.10.2/harbor-offline-installer-v1.10.2.tgz

tar  -zxf  harbor-offline-installer-v1.10.2.tgz
</code></pre>
<ol start="2">
<li>修改配置</li>
</ol>
<pre><code>修改 harbor.yml -&gt; hostname:改为本机ip， 修改http:port,  注释掉关于 https的配置，修改密码
</code></pre>
<ol start="3">
<li>安装docker-compose</li>
</ol>
<pre><code>yum -y install docker-compose
</code></pre>
<ol start="4">
<li>修改docker配置</li>
</ol>
<pre><code>systemctl status docker  找到docker路径

docker.service 中添加配置 -&gt; vim /usr/lib/systemd/system/docker.service 
        中 ExecStart= 后面添加上 --insecure-registry=39.101.174.47:5656
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://RookieYan.github.io/post-images/1587667006811.png" alt="" loading="lazy"></figure>
<p>这里如果这么配置，还是pull不下来镜像的话，就在 vim /etc/docker/daemon.json  这个目录下创建文件</p>
<pre><code>{
    &quot;insecure-registries&quot;: [&quot;0.0.0.0/0&quot;]
}
</code></pre>
<p>这样写就可以了。 （原因好像是因为 docker是https协议 而我们私有harbor是http导致的。）</p>
<ol start="5">
<li>重启docker</li>
</ol>
<pre><code>systemctl daemon-reload
systemctl restart docker
</code></pre>
<ol start="6">
<li>执行harbor的安装脚本，启动harbor</li>
</ol>
<pre><code>sh install.sh
</code></pre>
<ol start="7">
<li>登录harbor</li>
</ol>
<pre><code>docker login ip:port 用户名默认为admin 密码为自己修改配置文件设置好的
</code></pre>
<h2 id="6-编写脚本文件maven打包docker制作镜像依赖的是目录下的dockerfile"><strong>6.  编写脚本文件，maven打包+docker制作镜像（依赖的是目录下的Dockerfile）</strong></h2>
<ol>
<li>Dockerfile</li>
</ol>
<pre><code>FROM java:8-jdk-alpine
LABEL ceshi/www.ceshi.com
RUN apk upgrade
RUN  apk add -U  tzdata &amp;&amp; \
      ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
COPY ./target/cloud-data-center.jar ./
EXPOSE 12313
CMD java -jar /cloud-data-center.jar &gt; cloud-portal.log.out 2&gt;&amp;1
</code></pre>
<ol start="2">
<li>配置文件</li>
</ol>
<p>cloud-data-center.yaml</p>
<pre><code>---
apiVersion: apps/v1
kind: Deployment 
metadata:
  name: cloud-data-center
  namespace: kube-system 
spec:
  replicas: 1
  selector:
    matchLabels:
      project: kube-system
      app: cloud-data-center
  template:
    metadata:
      labels:
        project: kube-system 
        app: cloud-data-center
    spec:
      imagePullSecrets:
      - name: registry-pull-secret
      containers:
      - name: cloud-data-center
        image: 39.101.204.17:5656/k3s/cloud-data-center:2020-04-24-02-20-49
        imagePullPolicy: Always
        ports:
          - protocol: TCP
            containerPort: 12313
        env:
          - name: JAVA_OPTS
            value: &quot;-Xmx1G&quot;
        resources:
          requests:
            cpu: 0.1
            memory: 128Mi
          limits:
            cpu: 0.1
            memory: 1Gi
        readinessProbe:
          tcpSocket:
            port: 12313
          initialDelaySeconds: 60
          periodSeconds: 10
        livenessProbe:
          tcpSocket:
            port: 12313
          initialDelaySeconds: 60
          periodSeconds: 10
</code></pre>
<ol start="3">
<li>配置文件<br>
可以先执行， 执行方式为 kubectl apply -f cloud-data-center-ser.yaml</li>
</ol>
<pre><code>apiVersion: v1
kind: Service
metadata:
  name: cloud-data-center
  namespace: kube-system
spec:
  type: NodePort
  ports:
  - port: 12313
    name: cloud-data-center
  selector:
    project: kube-system
    app: cloud-data-center
</code></pre>
<ol start="4">
<li>脚本</li>
</ol>
<pre><code>#!/bin/bash
docker_registry=39.101.204.XXX:5656
kubectl create secret docker-registry registry-pull-secret --docker-server=$docker_registry --docker-username=user1 --docker-password=XXX --docker-email=XXX@qq.com -n kube-system
service=&quot;cloud-data-center&quot;
current_dir=$(pwd)
cd /data/cloud-data-center
echo ${current_dir}
# git checkout devops
# -b devops ssh://yanjianxun@47.93.249.XXX:29418/~admin/cloud-data-center.git
git pull
mvn -f /data/cloud-data-center/pom.xml clean
mvn -f /data/cloud-data-center/pom.xml install
image_name=$docker_registry/k3s/${service}:$(date +%F-%H-%M-%S)
sudo docker build -t ${image_name} .
sudo docker push ${image_name}
echo ${current_dir}
sed -i -r &quot;s#(image: )(.*)#\1$image_name#&quot; ${current_dir}/${service}/${service}.yaml
kubectl apply -f ${current_dir}/${service}/${service}.yaml
</code></pre>
<ol start="5">
<li>可以执行脚本</li>
<li>通过命令查看 pod状态</li>
</ol>
<pre><code>kubectl get -n kube-system pod   // -n 代表的是 namespace
</code></pre>
<ol start="7">
<li>如果容器运行出问题，可以到对应目录下（yaml文件同级下执行删除操作）</li>
</ol>
<pre><code>kubectl delete -f cloud-data-center.yaml
</code></pre>
<ol start="8">
<li>可以通过以下命令 进入到pod内部查看日志之类的</li>
</ol>
<pre><code>kubectl exec -it cloud-data-center-7d87586985-ftdgj -n kube-system -- /bin/sh
</code></pre>
<ol start="9">
<li>如果一切都正常的话 你应该可以看到 pod在running</li>
</ol>
<pre><code>kubectl get -n kube-system svc,pod   这个命令 可以看到你启动的容器在pod中映射出去的端口号，可以通过这个端口号访问容器内的接口和服务
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://RookieYan.github.io/post-images/1588516333372.png" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[[2020-04-18]MySQL（一）SQL的执行流程]]></title>
        <id>https://RookieYan.github.io/post/2020-04-18mysqlyi-sql-de-zhi-xing-liu-cheng/</id>
        <link href="https://RookieYan.github.io/post/2020-04-18mysqlyi-sql-de-zhi-xing-liu-cheng/">
        </link>
        <updated>2020-04-18T14:28:24.000Z</updated>
        <content type="html"><![CDATA[<p>  之前的由于不小心把所有的博客都删了，所以从0开始重新写吧。因为最近在看MySQL和MongoDB相关的，这篇就先从MySQL开始了.. 后续会继续补上MongoDB的内容..<br>
  这篇主要是讲一下MySQL的基础.. 包括语句的执行流程..</p>
<p><img src="https://RookieYan.github.io/post-images/1587222171337.png" alt="" loading="lazy"><br>
  首先简单介绍一下MySQL的基础结构图，可以从这张图清楚的看出一条语句在MySQL的各个功能模块中的执行过程。<br>
  大体来说MySQL 可以分为<strong>Server层</strong> 和 <strong>存储引擎层</strong>两部分。<br>
  Server层包含了连接器，分析器，优化器，执行器等.. 涵盖了大部分MySQL的核心功能，一级所有的内置函数（比如时间，日期，数学和加密函数等），所有跨存储引擎的功能都在这一层中，比如存储过程，触发器，视图等等..</p>
<p>  存储引擎层则负责数据的存储和提取。他的架构模式是插件式的，支持多种不同的数据库存储引擎，比如InnoDB，MyISAM，Memory等.. 现在比较常用的是InnoDB，在MySQL5.5.5开始成为了MySQL默认的存储引擎。</p>
<p>  也就是说你每次在创建表的时候，如果不指定存储引擎，就会默认使用InnoDB存储引擎。当然也可以自定义使用别的存储引擎，比如在 create table 语句中使用 engine=memory 来指定存储引擎创建表。<strong>不同的存储引擎对于数据的存取方式也不相同，支持的功能也不相同，在后面我们会说一下关于不同场景下不同存储引擎的选择。</strong></p>
<p>接下来介绍一下Server层的各个组件。</p>
<h2 id="连接器"><strong>连接器</strong></h2>
<p>  每次我们输入账号密码和MySQL要建立连接的时候，接待我们的就是<strong>连接器</strong>，他负责跟客户端建立连接，获取权限信息，维持和管理连接。一般的连接命令</p>
<pre><code>mysql -h$ip -P$port -u$user -p
</code></pre>
<ul>
<li>如果用户名或密码不对，你就会收到一个&quot;Access denied for user&quot;的错误，然后客户端程序结束执行。</li>
<li>如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。</li>
</ul>
<pre><code>这样也就意味着，只要一个客户通过连接器建立了与MySQL的连接，
再去对这个客户帐号进行权限上的操作，都不会即时生效，
只能等到这次连接结束，下次再建立连接的时候才会生效。
</code></pre>
<p>  如果建立完连接没有后续操作的话，那么这个连接就会处于空闲的状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。</p>
<p><img src="https://RookieYan.github.io/post-images/1587223843571.png" alt="" loading="lazy"><br>
  客户端如果太长时间没有动静，连接器就会自动断开它。 这个参数主要是由<strong>wait_timeout</strong>控制的，默认值是 8 小时。<br>
  而如果恰好在连接断开之后，客户端再次发送请求的话，就会收到错误提醒 Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。</p>
<p>   在数据库中，客户端与数据库建立连接的过程是十分复杂且消耗资源的，所以建议使用长链接（<strong>长链接是指如果在客户端与数据库连接成功后，如果客户端持续有请求进来，那么会继续使用当前已经建立好的这个连接。 而短连接主要是指，在每次执行完很少的几次操作后，就自动断开连接，如果再有新的请求，就重新建立连接。 这样比较消耗资源</strong>）， 但是如果全部使用长连接之后会发现数据库内存占用会涨的飞快，这是因为MySQL在执行过程中，临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才会释放。所以长连接积累下来就会导致内存占用率特别高，被系统强行干掉（OOM），从现象上看就像是MySQL异常重启了。</p>
<p>怎么解决这个问题呢？你可以考虑以下两种方案。</p>
<ul>
<li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li>
<li>如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li>
</ul>
<h2 id="查询缓存"><strong>查询缓存</strong></h2>
<p>   在通过连接器创建完连接之后，就要执行SQL命令了，比如一个查询语句，这个时候执行逻辑就会来到第二步，查询缓存。</p>
<p>   MySQL拿到一个查询请求后，会先到查询缓存看一下，之前是否执行过这条语句。 之前查询过的会以key-value对的形式，被直接缓存在内存中。key是查询语句，value是查询结果。 如果能够在缓存中找到这个key，那么这个value就会直接返回给客户端。</p>
<p>   如果语句不在查询缓存中，就会继续后面的执行阶段，进行查询。查询完成后执行结果就会被存储到查询缓存中。 可以看到，如果命中查询缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p>
<p><strong>但是在大多数情况下，是不建议使用查询缓存的，为什么呢？因为查询缓存网往弊大于利。</strong></p>
<p>   主要原因是因为查询缓存失效的概率非常大，为什么呢？因为每次只要对某一张表有更新操作，这个表上所有的查询缓存都会被清空。 因此可能你费劲把结果存起来之后，还没有用呢，一个更新语句就把缓存清空了。这样对于更新操作比较频繁的数据库来说，查询缓存的命中率会非常低。除非是一张静态的lookUp表，很长时间才会更新一次。比如系统配置表，行政区划表等表上的查询才会比较适合使用查询缓存。<br>
   好在MySQL也提供这种“按需使用”的方式，你可以将参数query_cache_type设置为DEMAND，这样对于默认的SQL语句都不使用查询缓存。 而对于你确定要使用查询缓存的语句可以用SQL_CACHE 显式指定，像下面这个语句一样：</p>
<pre><code>select SQL_CACHE * from T where ID=10；
</code></pre>
<ul>
<li>需要注意的是，MySQL8.0版本已经直接删除了查询缓存功能。</li>
</ul>
<h2 id="分析器"><strong>分析器</strong></h2>
<p>  如果没有命中查询缓存，就要开始真正执行SQL语句了，首先MySQL需要知道你要做什么，因此需要对MySQL语句做解析。<br>
  分析器会现做“词法解析”，你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。</p>
<p>  MySQL 从你输入的&quot;select&quot;这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。<br>
  做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。<br>
  如果你的语句不对，就会收到“You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。</p>
<pre><code>
mysql&gt; elect * from t where ID=1;

ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1
</code></pre>
<p>一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。</p>
<p><strong><a href="https://tech.meituan.com/2018/05/20/sql-parser-used-in-mtdp.html">详细语法SQL解析流程，来自美团技术团队，点击跳转</a></strong></p>
<h2 id="优化器"><strong>优化器</strong></h2>
<p>  经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。<br>
  优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join：</p>
<pre><code>mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;
</code></pre>
<ul>
<li>既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。</li>
<li>也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。</li>
</ul>
<p>优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。如果你还有一些疑问，比如优化器是怎么选择索引的，有没有可能选择错等等，我会在后面的博客中单独展开说明优化器的内容。</p>
<h2 id="执行器"><strong>执行器</strong></h2>
<p>  MySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。<br>
  开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。</p>
<pre><code>mysql&gt; select * from T where ID=10;ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
</code></pre>
<p>  如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。<br>
  比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：</p>
<ul>
<li>调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；</li>
<li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li>
<li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li>
</ul>
<p>  至此，这个语句就执行完成了。对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。<br>
  你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。<br>
  在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。我们后面会专门有一篇文章来讲存储引擎的内部机制，里面会有详细的说明。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[[2020-04-11]重新开始]]></title>
        <id>https://RookieYan.github.io/post/2020-04-11chong-xin-kai-shi/</id>
        <link href="https://RookieYan.github.io/post/2020-04-11chong-xin-kai-shi/">
        </link>
        <updated>2020-04-11T14:49:04.000Z</updated>
        <content type="html"><![CDATA[<p>  之前因为搭了一个Ngrok，被黑客扫到了，把电脑黑了。然后今天重装了系统，格式化了硬盘，一不小心把博客也都清了... 没办法...  回不去的就留在过去吧...  重新写....</p>
<p>  加油...</p>
]]></content>
    </entry>
</feed>